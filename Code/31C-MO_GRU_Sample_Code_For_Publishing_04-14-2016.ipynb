{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Gated Recurrent Units (GRU) in Theano - 4/14/2016\n",
    "Reference:  http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/   \n",
    "Reference:  https://github.com/dennybritz/rnn-tutorial-gru-lstm/blob/master/gru_theano.py   \n",
    "Data for Unit Test:  https://github.com/maoneto/W210/blob/master/Code/data/reddit-comments-2015-trunc.csv   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Unit Test from Denny Britz Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GRUTheano Class for Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gru_theano_ut.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gru_theano_ut.py\n",
    "\n",
    "import numpy as np\n",
    "import theano as theano\n",
    "import theano.tensor as T\n",
    "from theano.gradient import grad_clip\n",
    "import time\n",
    "import operator\n",
    "\n",
    "class GRUTheanoUT:\n",
    "    \n",
    "    def __init__(self, word_dim, hidden_dim=128, bptt_truncate=-1):\n",
    "        # Assign instance variables\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # Initialize the network parameters\n",
    "        E = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (hidden_dim, word_dim))\n",
    "        U = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (6, hidden_dim, hidden_dim))\n",
    "        W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (6, hidden_dim, hidden_dim))\n",
    "        V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
    "        b = np.zeros((6, hidden_dim))\n",
    "        c = np.zeros(word_dim)\n",
    "        # Theano: Created shared variables\n",
    "        self.E = theano.shared(name='E', value=E.astype(theano.config.floatX))\n",
    "        self.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "        self.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "        self.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
    "        self.b = theano.shared(name='b', value=b.astype(theano.config.floatX))\n",
    "        self.c = theano.shared(name='c', value=c.astype(theano.config.floatX))\n",
    "        # SGD / rmsprop: Initialize parameters\n",
    "        self.mE = theano.shared(name='mE', value=np.zeros(E.shape).astype(theano.config.floatX))\n",
    "        self.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "        self.mV = theano.shared(name='mV', value=np.zeros(V.shape).astype(theano.config.floatX))\n",
    "        self.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "        self.mb = theano.shared(name='mb', value=np.zeros(b.shape).astype(theano.config.floatX))\n",
    "        self.mc = theano.shared(name='mc', value=np.zeros(c.shape).astype(theano.config.floatX))\n",
    "        # We store the Theano graph here\n",
    "        self.theano = {}\n",
    "        self.__theano_build__()\n",
    "    \n",
    "    def __theano_build__(self):\n",
    "        E, V, U, W, b, c = self.E, self.V, self.U, self.W, self.b, self.c\n",
    "        \n",
    "        x = T.ivector('x')\n",
    "        y = T.ivector('y')\n",
    "        \n",
    "        def forward_prop_step(x_t, s_t1_prev, s_t2_prev):\n",
    "            # This is how we calculated the hidden state in a simple RNN. No longer!\n",
    "            # s_t = T.tanh(U[:,x_t] + W.dot(s_t1_prev))\n",
    "            \n",
    "            # Word embedding layer\n",
    "            x_e = E[:,x_t]\n",
    "            \n",
    "            # GRU Layer 1\n",
    "            z_t1 = T.nnet.hard_sigmoid(U[0].dot(x_e) + W[0].dot(s_t1_prev) + b[0])\n",
    "            r_t1 = T.nnet.hard_sigmoid(U[1].dot(x_e) + W[1].dot(s_t1_prev) + b[1])\n",
    "            c_t1 = T.tanh(U[2].dot(x_e) + W[2].dot(s_t1_prev * r_t1) + b[2])\n",
    "            s_t1 = (T.ones_like(z_t1) - z_t1) * c_t1 + z_t1 * s_t1_prev\n",
    "            \n",
    "            # GRU Layer 2\n",
    "            z_t2 = T.nnet.hard_sigmoid(U[3].dot(s_t1) + W[3].dot(s_t2_prev) + b[3])\n",
    "            r_t2 = T.nnet.hard_sigmoid(U[4].dot(s_t1) + W[4].dot(s_t2_prev) + b[4])\n",
    "            c_t2 = T.tanh(U[5].dot(s_t1) + W[5].dot(s_t2_prev * r_t2) + b[5])\n",
    "            s_t2 = (T.ones_like(z_t2) - z_t2) * c_t2 + z_t2 * s_t2_prev\n",
    "            \n",
    "            # Final output calculation\n",
    "            # Theano's softmax returns a matrix with one row, we only need the row\n",
    "            o_t = T.nnet.softmax(V.dot(s_t2) + c)[0]\n",
    "\n",
    "            return [o_t, s_t1, s_t2]\n",
    "        \n",
    "        [o, s, s2], updates = theano.scan(\n",
    "            forward_prop_step,\n",
    "            sequences=x,\n",
    "            truncate_gradient=self.bptt_truncate,\n",
    "            outputs_info=[None, \n",
    "                          dict(initial=T.zeros(self.hidden_dim)),\n",
    "                          dict(initial=T.zeros(self.hidden_dim))])\n",
    "        \n",
    "        prediction = T.argmax(o, axis=1)\n",
    "        o_error = T.sum(T.nnet.categorical_crossentropy(o, y))\n",
    "        \n",
    "        # Total cost (could add regularization here)\n",
    "        cost = o_error\n",
    "        \n",
    "        # Gradients\n",
    "        dE = T.grad(cost, E)\n",
    "        dU = T.grad(cost, U)\n",
    "        dW = T.grad(cost, W)\n",
    "        db = T.grad(cost, b)\n",
    "        dV = T.grad(cost, V)\n",
    "        dc = T.grad(cost, c)\n",
    "        \n",
    "        # Assign functions\n",
    "        self.predict = theano.function([x], o)\n",
    "        self.predict_class = theano.function([x], prediction)\n",
    "        self.ce_error = theano.function([x, y], cost)\n",
    "        self.bptt = theano.function([x, y], [dE, dU, dW, db, dV, dc])\n",
    "        \n",
    "        # SGD parameters\n",
    "        learning_rate = T.scalar('learning_rate')\n",
    "        decay = T.scalar('decay')\n",
    "        \n",
    "        # rmsprop cache updates\n",
    "        mE = decay * self.mE + (1 - decay) * dE ** 2\n",
    "        mU = decay * self.mU + (1 - decay) * dU ** 2\n",
    "        mW = decay * self.mW + (1 - decay) * dW ** 2\n",
    "        mV = decay * self.mV + (1 - decay) * dV ** 2\n",
    "        mb = decay * self.mb + (1 - decay) * db ** 2\n",
    "        mc = decay * self.mc + (1 - decay) * dc ** 2\n",
    "        \n",
    "        self.sgd_step = theano.function(\n",
    "            [x, y, learning_rate, theano.Param(decay, default=0.9)],\n",
    "            [], \n",
    "            updates=[(E, E - learning_rate * dE / T.sqrt(mE + 1e-6)),\n",
    "                     (U, U - learning_rate * dU / T.sqrt(mU + 1e-6)),\n",
    "                     (W, W - learning_rate * dW / T.sqrt(mW + 1e-6)),\n",
    "                     (V, V - learning_rate * dV / T.sqrt(mV + 1e-6)),\n",
    "                     (b, b - learning_rate * db / T.sqrt(mb + 1e-6)),\n",
    "                     (c, c - learning_rate * dc / T.sqrt(mc + 1e-6)),\n",
    "                     (self.mE, mE),\n",
    "                     (self.mU, mU),\n",
    "                     (self.mW, mW),\n",
    "                     (self.mV, mV),\n",
    "                     (self.mb, mb),\n",
    "                     (self.mc, mc)\n",
    "                    ])\n",
    "        \n",
    "        \n",
    "    def calculate_total_loss(self, X, Y):\n",
    "        return np.sum([self.ce_error(x,y) for x,y in zip(X,Y)])\n",
    "    \n",
    "    def calculate_loss(self, X, Y):\n",
    "        # Divide calculate_loss by the number of words\n",
    "        num_words = np.sum([len(y) for y in Y])\n",
    "        return self.calculate_total_loss(X,Y)/float(num_words)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Theano Utility Functions from utils.py for Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils_ut.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils_ut.py\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "import sys\n",
    "import operator\n",
    "import io\n",
    "import array\n",
    "from datetime import datetime\n",
    "from gru_theano_ut import GRUTheanoUT\n",
    "\n",
    "SENTENCE_START_TOKEN = \"SENTENCE_START\"\n",
    "SENTENCE_END_TOKEN = \"SENTENCE_END\"\n",
    "UNKNOWN_TOKEN = \"UNKNOWN_TOKEN\"\n",
    "\n",
    "def load_data(filename, vocabulary_size=2000, min_sent_characters=0):\n",
    "\n",
    "    word_to_index = []\n",
    "    index_to_word = []\n",
    "\n",
    "    # Read the data and append SENTENCE_START and SENTENCE_END tokens\n",
    "    print(\"Reading CSV file...\")\n",
    "    with open(filename, 'rt') as f:\n",
    "        reader = csv.reader(f, skipinitialspace=True)\n",
    "        reader.next()\n",
    "        # Split full comments into sentences\n",
    "        sentences = itertools.chain(*[nltk.sent_tokenize(x[0].decode(\"utf-8\").lower()) for x in reader])\n",
    "        # Filter sentences\n",
    "        sentences = [s for s in sentences if len(s) >= min_sent_characters]\n",
    "        sentences = [s for s in sentences if \"http\" not in s]\n",
    "        # Append SENTENCE_START and SENTENCE_END\n",
    "        sentences = [\"%s %s %s\" % (SENTENCE_START_TOKEN, x, SENTENCE_END_TOKEN) for x in sentences]\n",
    "    print(\"Parsed %d sentences.\" % (len(sentences)))\n",
    "\n",
    "    # Tokenize the sentences into words\n",
    "    tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # Count the word frequencies\n",
    "    word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "    print(\"Found %d unique words tokens.\" % len(word_freq.items()))\n",
    "\n",
    "    # Get the most common words and build index_to_word and word_to_index vectors\n",
    "    vocab = sorted(word_freq.items(), key=lambda x: (x[1], x[0]), reverse=True)[:vocabulary_size-2]\n",
    "    print(\"Using vocabulary size %d.\" % vocabulary_size)\n",
    "    print(\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1]))\n",
    "\n",
    "    sorted_vocab = sorted(vocab, key=operator.itemgetter(1))\n",
    "    index_to_word = [\"<MASK/>\", UNKNOWN_TOKEN] + [x[0] for x in sorted_vocab]\n",
    "    word_to_index = dict([(w, i) for i, w in enumerate(index_to_word)])\n",
    "\n",
    "    # Replace all words not in our vocabulary with the unknown token\n",
    "    for i, sent in enumerate(tokenized_sentences):\n",
    "        tokenized_sentences[i] = [w if w in word_to_index else UNKNOWN_TOKEN for w in sent]\n",
    "\n",
    "    # Create the training data\n",
    "    X_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in tokenized_sentences])\n",
    "    y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in tokenized_sentences])\n",
    "\n",
    "    return X_train, y_train, word_to_index, index_to_word\n",
    "\n",
    "\n",
    "def train_with_sgd(model, X_train, y_train, learning_rate=0.001, nepoch=20, decay=0.9,\n",
    "    callback_every=10000, callback=None):\n",
    "    num_examples_seen = 0\n",
    "    for epoch in range(nepoch):\n",
    "        # For each training example...\n",
    "        for i in np.random.permutation(len(y_train)):\n",
    "            # One SGD step\n",
    "            model.sgd_step(X_train[i], y_train[i], learning_rate, decay)\n",
    "            num_examples_seen += 1\n",
    "            # Optionally do callback\n",
    "            if (callback and callback_every and num_examples_seen % callback_every == 0):\n",
    "                callback(model, num_examples_seen)            \n",
    "    return model\n",
    "\n",
    "def save_model_parameters_theano(model, outfile):\n",
    "    np.savez(outfile,\n",
    "        E=model.E.get_value(),\n",
    "        U=model.U.get_value(),\n",
    "        W=model.W.get_value(),\n",
    "        V=model.V.get_value(),\n",
    "        b=model.b.get_value(),\n",
    "        c=model.c.get_value())\n",
    "    print \"Saved model parameters to %s.\" % outfile\n",
    "\n",
    "def load_model_parameters_theano(path, modelClass=GRUTheanoUT):\n",
    "    npzfile = np.load(path)\n",
    "    E, U, W, V, b, c = npzfile[\"E\"], npzfile[\"U\"], npzfile[\"W\"], npzfile[\"V\"], npzfile[\"b\"], npzfile[\"c\"]\n",
    "    hidden_dim, word_dim = E.shape[0], E.shape[1]\n",
    "    print \"Building model model from %s with hidden_dim=%d word_dim=%d\" % (path, hidden_dim, word_dim)\n",
    "    sys.stdout.flush()\n",
    "    model = modelClass(word_dim, hidden_dim=hidden_dim)\n",
    "    model.E.set_value(E)\n",
    "    model.U.set_value(U)\n",
    "    model.W.set_value(W)\n",
    "    model.V.set_value(V)\n",
    "    model.b.set_value(b)\n",
    "    model.c.set_value(c)\n",
    "    return model \n",
    "\n",
    "def gradient_check_theano(model, x, y, h=0.001, error_threshold=0.01):\n",
    "    # Overwrite the bptt attribute. We need to backpropagate all the way to get the correct gradient\n",
    "    model.bptt_truncate = 1000\n",
    "    # Calculate the gradients using backprop\n",
    "    bptt_gradients = model.bptt(x, y)\n",
    "    # List of all parameters we want to chec.\n",
    "    model_parameters = ['E', 'U', 'W', 'b', 'V', 'c']\n",
    "    # Gradient check for each parameter\n",
    "    for pidx, pname in enumerate(model_parameters):\n",
    "        # Get the actual parameter value from the mode, e.g. model.W\n",
    "        parameter_T = operator.attrgetter(pname)(model)\n",
    "        parameter = parameter_T.get_value()\n",
    "        print \"Performing gradient check for parameter %s with size %d.\" % (pname, np.prod(parameter.shape))\n",
    "        # Iterate over each element of the parameter matrix, e.g. (0,0), (0,1), ...\n",
    "        it = np.nditer(parameter, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        while not it.finished:\n",
    "            ix = it.multi_index\n",
    "            # Save the original value so we can reset it later\n",
    "            original_value = parameter[ix]\n",
    "            # Estimate the gradient using (f(x+h) - f(x-h))/(2*h)\n",
    "            parameter[ix] = original_value + h\n",
    "            parameter_T.set_value(parameter)\n",
    "            gradplus = model.calculate_total_loss([x],[y])\n",
    "            parameter[ix] = original_value - h\n",
    "            parameter_T.set_value(parameter)\n",
    "            gradminus = model.calculate_total_loss([x],[y])\n",
    "            estimated_gradient = (gradplus - gradminus)/(2*h)\n",
    "            parameter[ix] = original_value\n",
    "            parameter_T.set_value(parameter)\n",
    "            # The gradient for this parameter calculated using backpropagation\n",
    "            backprop_gradient = bptt_gradients[pidx][ix]\n",
    "            # calculate The relative error: (|x - y|/(|x| + |y|))\n",
    "            relative_error = np.abs(backprop_gradient - estimated_gradient)/(np.abs(backprop_gradient) + np.abs(estimated_gradient))\n",
    "            # If the error is to large fail the gradient check\n",
    "            if relative_error > error_threshold:\n",
    "                print \"Gradient Check ERROR: parameter=%s ix=%s\" % (pname, ix)\n",
    "                print \"+h Loss: %f\" % gradplus\n",
    "                print \"-h Loss: %f\" % gradminus\n",
    "                print \"Estimated_gradient: %f\" % estimated_gradient\n",
    "                print \"Backpropagation gradient: %f\" % backprop_gradient\n",
    "                print \"Relative Error: %f\" % relative_error\n",
    "                return \n",
    "            it.iternext()\n",
    "        print \"Gradient check for parameter %s passed.\" % (pname)\n",
    "\n",
    "\n",
    "def print_sentence(s, index_to_word):\n",
    "    sentence_str = [index_to_word[x] for x in s[1:-1]]\n",
    "    print(\" \".join(sentence_str))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def generate_sentence(model, index_to_word, word_to_index, min_length=5):\n",
    "    # We start the sentence with the start token\n",
    "    new_sentence = [word_to_index[SENTENCE_START_TOKEN]]\n",
    "    # Repeat until we get an end token\n",
    "    while not new_sentence[-1] == word_to_index[SENTENCE_END_TOKEN]:\n",
    "        next_word_probs = model.predict(new_sentence)[-1]\n",
    "        samples = np.random.multinomial(1, next_word_probs)\n",
    "        sampled_word = np.argmax(samples)\n",
    "        new_sentence.append(sampled_word)\n",
    "        # Seomtimes we get stuck if the sentence becomes too long, e.g. \"........\" :(\n",
    "        # And: We don't want sentences with UNKNOWN_TOKEN's\n",
    "        if len(new_sentence) > 100 or sampled_word == word_to_index[UNKNOWN_TOKEN]:\n",
    "            return None\n",
    "    if len(new_sentence) < min_length:\n",
    "        return None\n",
    "    return new_sentence\n",
    "\n",
    "def generate_sentences(model, n, index_to_word, word_to_index):\n",
    "    for i in range(n):\n",
    "        sent = None\n",
    "        while not sent:\n",
    "            sent = generate_sentence(model, index_to_word, word_to_index)\n",
    "        print_sentence(sent, index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GRU for Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file...\n",
      "Parsed 94 sentences.\n",
      "Found 632 unique words tokens.\n",
      "Using vocabulary size 200.\n",
      "The least frequent word in our vocabulary is 'we' and appeared 1 times.\n",
      "SGD Step time: 62.611103 milliseconds\n",
      "\n",
      "2016-04-10T15:17:13.638628 (25)\n",
      "--------------------------------------------------\n",
      "Loss: 4.184149\n",
      ". to i 're could better\n",
      "or que per available for ``\n",
      "happens with of s ( see\n",
      "will have . .\n",
      "yellow they can after\n",
      "zerefs $ on -\n",
      "'' stream bills he has seen and . although whole\n",
      "-- by because riven than\n",
      "! available did joking cost lidstrom welcome think though\n",
      "could a in users happens cost right its\n",
      "Saved model parameters to GRU-2016-04-10-15-15-200-48-128.dat.\n",
      "\n",
      "\n",
      "\n",
      "2016-04-10T15:17:14.904741 (50)\n",
      "--------------------------------------------------\n",
      "Loss: 3.965305\n",
      "there and try ones seen the widevision per with season\n",
      "wrong cost joke of '' - it\n",
      "tourist happens where ( he .\n",
      "classic that cash is other by each\n",
      "character better it the\n",
      "my has '' '\n",
      "( ( same more , that know\n",
      "'' will more try in\n",
      "something really on better stream , that was the . $\n",
      "about back welcome that people\n",
      "Saved model parameters to GRU-2016-04-10-15-15-200-48-128.dat.\n",
      "\n",
      "\n",
      "\n",
      "2016-04-10T15:17:16.328531 (75)\n",
      "--------------------------------------------------\n",
      "Loss: 3.939875\n",
      "hit and )\n",
      "be there , cost could .\n",
      "competition me have end when\n",
      "overlap the happens\n",
      "this paul with . year tone\n",
      "however will 's with was a i\n",
      "value joke if\n",
      "exactly the that\n",
      "bill out back there it\n",
      "back paul , . . ,\n",
      "Saved model parameters to GRU-2016-04-10-15-15-200-48-128.dat.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from utils_ut import *\n",
    "from datetime import datetime\n",
    "from gru_theano_ut import GRUTheanoUT\n",
    "\n",
    "LEARNING_RATE = float(os.environ.get(\"LEARNING_RATE\", \"0.001\"))\n",
    "VOCABULARY_SIZE = int(os.environ.get(\"VOCABULARY_SIZE\", \"200\"))\n",
    "EMBEDDING_DIM = int(os.environ.get(\"EMBEDDING_DIM\", \"48\"))\n",
    "HIDDEN_DIM = int(os.environ.get(\"HIDDEN_DIM\", \"128\"))\n",
    "NEPOCH = int(os.environ.get(\"NEPOCH\", \"1\"))\n",
    "MODEL_OUTPUT_FILE = os.environ.get(\"MODEL_OUTPUT_FILE\")\n",
    "INPUT_DATA_FILE = os.environ.get(\"INPUT_DATA_FILE\", \"./data/reddit-comments-2015-trunc.csv\")\n",
    "PRINT_EVERY = int(os.environ.get(\"PRINT_EVERY\", \"25\"))\n",
    "\n",
    "if not MODEL_OUTPUT_FILE:\n",
    "  ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "  MODEL_OUTPUT_FILE = \"GRU-%s-%s-%s-%s.dat\" % (ts, VOCABULARY_SIZE, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "\n",
    "# Load data\n",
    "x_train, y_train, word_to_index, index_to_word = load_data(INPUT_DATA_FILE, VOCABULARY_SIZE)\n",
    "\n",
    "# Build model\n",
    "model = GRUTheanoUT(VOCABULARY_SIZE, hidden_dim=HIDDEN_DIM, bptt_truncate=-1)\n",
    "\n",
    "# Print SGD step time\n",
    "t1 = time.time()\n",
    "model.sgd_step(x_train[10], y_train[10], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print \"SGD Step time: %f milliseconds\" % ((t2 - t1) * 1000.)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# We do this every few examples to understand what's going on\n",
    "def sgd_callback(model, num_examples_seen):\n",
    "  dt = datetime.now().isoformat()\n",
    "  loss = model.calculate_loss(x_train[:10000], y_train[:10000])\n",
    "  print(\"\\n%s (%d)\" % (dt, num_examples_seen))\n",
    "  print(\"--------------------------------------------------\")\n",
    "  print(\"Loss: %f\" % loss)\n",
    "  generate_sentences(model, 10, index_to_word, word_to_index)\n",
    "  save_model_parameters_theano(model, MODEL_OUTPUT_FILE)\n",
    "  print(\"\\n\")\n",
    "  sys.stdout.flush()\n",
    "\n",
    "for epoch in range(NEPOCH):\n",
    "  train_with_sgd(model, x_train, y_train, learning_rate=LEARNING_RATE, nepoch=1, decay=0.9, \n",
    "    callback_every=PRINT_EVERY, callback=sgd_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU for Yield Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training, Validation, and Test Datasets for Yield Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and X_test Shape:\n",
      "(8000, 7) (2000, 7)\n",
      "Y_train, Y_test, log_Y_train, log_Y_test Shape:\n",
      "(8000, 7) (2000, 7) (8000, 7) (2000, 7)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "with open('train_trajectories_11_images_max_mv_trunc10000.csv', 'r') as csvfile: # currently, this dataset is proprietary and cannot be shared   \n",
    "    datareader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in datareader:\n",
    "        label = row.pop()  ## pop the last element in the list which is the label (yield calc)\n",
    "        if float(label) != 0.0:\n",
    "            X.append(row)\n",
    "            Y.append(len(X[0])*[label]) # output at each t (o_t) is the yield\n",
    "X = np.array(X).astype(np.float)\n",
    "Y = np.array(Y).astype(np.float)\n",
    "\n",
    "# Break labeled examples into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=22)\n",
    "\n",
    "# Transform target variable\n",
    "log_Y_train = np.log(Y_train)\n",
    "log_Y_test = np.log(Y_test)\n",
    "\n",
    "print \"X_train and X_test Shape:\"\n",
    "print X_train.shape, X_test.shape\n",
    "\n",
    "print \"Y_train, Y_test, log_Y_train, log_Y_test Shape:\"\n",
    "print Y_train.shape, Y_test.shape, log_Y_train.shape, log_Y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GRUTheano Class for Yield Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gru_theano_yp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gru_theano_yp.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import theano as theano\n",
    "import theano.tensor as T\n",
    "from theano.gradient import grad_clip\n",
    "import time\n",
    "import operator\n",
    "\n",
    "theano.exception_verbosity='high'\n",
    "theano.mode='FAST_COMPILE'\n",
    "theano.allow_gc=False\n",
    "theano.optimizer='fast_compile'\n",
    "theano.config.compute_test_value = 'off'\n",
    "\n",
    "class GRUTheanoYP:\n",
    "    \n",
    "    def __init__(self, word_dim, hidden_dim=128, bptt_truncate=-1):\n",
    "        # Assign instance variables\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # Initialize the network parameters\n",
    "        E = np.random.uniform(-np.sqrt(1./100000), np.sqrt(1./100000), (hidden_dim, word_dim))\n",
    "        U = np.random.uniform(-np.sqrt(1./100000), np.sqrt(1./100000), (6, hidden_dim, hidden_dim))\n",
    "        W = np.random.uniform(-np.sqrt(1./100000), np.sqrt(1./100000), (6, hidden_dim, hidden_dim))\n",
    "        V = np.random.uniform(-np.sqrt(1./100000), np.sqrt(1./100000), (word_dim, hidden_dim))\n",
    "        b = np.zeros((6, hidden_dim, 1))\n",
    "        c = np.zeros((word_dim, 1))\n",
    "        # Theano: Created shared variables\n",
    "        self.E = theano.shared(name='E', value=E.astype(theano.config.floatX))\n",
    "        self.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "        self.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "        self.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
    "        self.b = theano.shared(name='b', value=b.astype(theano.config.floatX))\n",
    "        self.c = theano.shared(name='c', value=c.astype(theano.config.floatX))\n",
    "        # SGD / rmsprop: Initialize parameters\n",
    "        self.mE = theano.shared(name='mE', value=np.zeros(E.shape).astype(theano.config.floatX))\n",
    "        self.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "        self.mV = theano.shared(name='mV', value=np.zeros(V.shape).astype(theano.config.floatX))\n",
    "        self.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "        self.mb = theano.shared(name='mb', value=np.zeros(b.shape).astype(theano.config.floatX))\n",
    "        self.mc = theano.shared(name='mc', value=np.zeros(c.shape).astype(theano.config.floatX))\n",
    "        # We store the Theano graph here\n",
    "        self.theano = {}\n",
    "        self.__theano_build__()\n",
    "    \n",
    "    def __theano_build__(self):\n",
    "        E, V, U, W, b, c = self.E, self.V, self.U, self.W, self.b, self.c\n",
    "        \n",
    "        x = T.vector('x')\n",
    "        y = T.vector('y')\n",
    "        \n",
    "        def forward_prop_step(x_t, s_t1_prev, s_t2_prev):\n",
    "            # This is how we calculated the hidden state in a simple RNN. No longer!\n",
    "            # s_t = T.tanh(U[:,x_t] + W.dot(s_t1_prev))\n",
    "            \n",
    "            # Word embedding layer\n",
    "            x_e = T.mul(E, x_t)\n",
    "            \n",
    "            # GRU Layer 1\n",
    "            z_t1 = T.nnet.hard_sigmoid(T.dot(U[0], x_e) + T.dot(W[0], s_t1_prev) + b[0])\n",
    "            r_t1 = T.nnet.hard_sigmoid(T.dot(U[1], x_e) + T.dot(W[1], s_t1_prev) + b[1])\n",
    "            c_t1 = T.tanh(T.dot(U[2], x_e) + W[2].dot(s_t1_prev * r_t1) + b[2])\n",
    "            s_t1 = (T.ones_like(z_t1) - z_t1) * c_t1 + z_t1 * s_t1_prev\n",
    "#             print T.shape(s_t1).eval({x_t: 0.8888, s_t1_prev: np.asarray([[0], [0], [0], [0], [0]])})     \n",
    "            # GRU Layer 2\n",
    "            z_t2 = T.nnet.hard_sigmoid(U[3].dot(s_t1) + W[3].dot(s_t2_prev) + b[3])\n",
    "            r_t2 = T.nnet.hard_sigmoid(U[4].dot(s_t1) + W[4].dot(s_t2_prev) + b[4])\n",
    "            c_t2 = T.tanh(U[5].dot(s_t1) + W[5].dot(s_t2_prev * r_t2) + b[5])\n",
    "            s_t2 = (T.ones_like(z_t2) - z_t2) * c_t2 + z_t2 * s_t2_prev\n",
    "            \n",
    "            # Final output calculation\n",
    "            # Theano's softmax returns a matrix with one row, we only need the row\n",
    "            # o_t = T.nnet.softmax(V.dot(s_t2) + c)[0]\n",
    "            # We are predicting a continuous variable (yield), not a class, so we need to change the equation to calculate the outcome at time t  \n",
    "            o_t = (V.dot(s_t2) + c)[0]\n",
    "\n",
    "            return [o_t, s_t1, s_t2]\n",
    "        \n",
    "        [o, s, s2], updates = theano.scan(\n",
    "            forward_prop_step,\n",
    "            sequences=[x],\n",
    "            truncate_gradient=self.bptt_truncate,\n",
    "            outputs_info=[None, \n",
    "                          dict(initial=T.zeros_like(E)),\n",
    "                          dict(initial=T.zeros_like(E))])\n",
    "        \n",
    "        # prediction = T.argmax(o, axis=1)\n",
    "        # o_error = T.sum(T.nnet.categorical_crossentropy(o, y))\n",
    "        # Again, we are predicting a continuous variable (yield), not a class, so we change the prediction\n",
    "        # and use sum of squared errors (sse) as our objective function\n",
    "        prediction = o\n",
    "        o_error = T.sum(T.sqr(o - T.reshape(y, [T.shape(y)[0],1,1], ndim=3)))\n",
    "        \n",
    "        # Total cost (could add regularization here)\n",
    "        cost = o_error\n",
    "        \n",
    "        # Gradients\n",
    "        dE = T.grad(cost, E)\n",
    "        dU = T.grad(cost, U)\n",
    "        dW = T.grad(cost, W)\n",
    "        db = T.grad(cost, b)\n",
    "        dV = T.grad(cost, V)\n",
    "        dc = T.grad(cost, c)\n",
    "        \n",
    "        # Assign functions\n",
    "        self.predict = theano.function([x], o)\n",
    "#         self.predict_class = theano.function([x], prediction)\n",
    "        self.sse_error = theano.function([x, y], cost)\n",
    "        self.bptt = theano.function([x, y], [dU, dW, db, dV, dc])\n",
    "        \n",
    "        # SGD parameters\n",
    "        learning_rate = T.scalar('learning_rate')\n",
    "        decay = T.scalar('decay')\n",
    "        \n",
    "        # rmsprop cache updates\n",
    "        mE = decay * self.mE + (1 - decay) * dE ** 2\n",
    "        mU = decay * self.mU + (1 - decay) * dU ** 2\n",
    "        mW = decay * self.mW + (1 - decay) * dW ** 2\n",
    "        mV = decay * self.mV + (1 - decay) * dV ** 2\n",
    "        mb = decay * self.mb + (1 - decay) * db ** 2\n",
    "        mc = decay * self.mc + (1 - decay) * dc ** 2\n",
    "        \n",
    "        self.sgd_step = theano.function(\n",
    "            [x, y, learning_rate, theano.Param(decay, default=0.9)],\n",
    "            [], \n",
    "            updates=[(U, U - learning_rate * dU / T.sqrt(mU + 1e-6)),\n",
    "                     (W, W - learning_rate * dW / T.sqrt(mW + 1e-6)),\n",
    "                     (V, V - learning_rate * dV / T.sqrt(mV + 1e-6)),\n",
    "                     (b, b - learning_rate * db / T.sqrt(mb + 1e-6)),\n",
    "                     (c, c - learning_rate * dc / T.sqrt(mc + 1e-6)),\n",
    "                     (self.mU, mU),\n",
    "                     (self.mW, mW),\n",
    "                     (self.mV, mV),\n",
    "                     (self.mb, mb),\n",
    "                     (self.mc, mc)\n",
    "                    ])\n",
    "        \n",
    "        \n",
    "    def calculate_total_loss(self, X, Y):\n",
    "        return np.sum([self.sse_error(x,y) for x,y in zip(X,Y)])\n",
    "    \n",
    "    def calculate_loss(self, X, Y):\n",
    "        # Divide calculate_loss by the number of words\n",
    "        num_words = np.sum([len(y) for y in Y])\n",
    "        return self.calculate_total_loss(X,Y)/float(num_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Theano Utility Functions from utils.py for Yield Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils_yp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils_yp.py\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "import sys\n",
    "import operator\n",
    "import io\n",
    "import array\n",
    "from datetime import datetime\n",
    "from gru_theano_yp import GRUTheanoYP\n",
    "\n",
    "def shuffle_data(p, X, y):\n",
    "        # shuffle it\n",
    "        shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "        X, y = X[shuffle], y[shuffle]\n",
    "        # divide \n",
    "        n_train = np.round(X.shape[0]*p)\n",
    "        return X[:n_train], y[:n_train], X[n_train:], y[n_train:]\n",
    "\n",
    "def save_model_parameters_theano(model, outfile):\n",
    "    np.savez(outfile,\n",
    "        E=model.E.get_value(),\n",
    "        U=model.U.get_value(),\n",
    "        W=model.W.get_value(),\n",
    "        V=model.V.get_value(),\n",
    "        b=model.b.get_value(),\n",
    "        c=model.c.get_value())\n",
    "#     print \"Saved model parameters to %s.\" % outfile\n",
    "\n",
    "def load_model_parameters_theano(path, modelClass=GRUTheanoYP):\n",
    "    npzfile = np.load(path)\n",
    "    E, U, W, V, b, c = npzfile[\"E\"], npzfile[\"U\"], npzfile[\"W\"], npzfile[\"V\"], npzfile[\"b\"], npzfile[\"c\"]\n",
    "    hidden_dim, word_dim = E.shape[0], E.shape[1]\n",
    "    print \"Building model model from %s with hidden_dim=%d word_dim=%d\" % (path, hidden_dim, word_dim)\n",
    "    sys.stdout.flush()\n",
    "    model = modelClass(word_dim, hidden_dim=hidden_dim)\n",
    "    model.E.set_value(E)\n",
    "    model.U.set_value(U)\n",
    "    model.W.set_value(W)\n",
    "    model.V.set_value(V)\n",
    "    model.b.set_value(b)\n",
    "    model.c.set_value(c)\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GRU for Yield Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmphWe9RS/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmphWe9RS/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp5ibKyW/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp5ibKyW/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpSpONwq/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpSpONwq/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpP9KXUv/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpP9KXUv/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp0cikD3/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp0cikD3/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpOuJ3FM/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpOuJ3FM/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpWkBLlu/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpWkBLlu/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp1XhEQu/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp1XhEQu/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpV_s7Qk/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpV_s7Qk/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmppSCc6h/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmppSCc6h/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpLccDrE/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpLccDrE/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpHsoOup/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpHsoOup/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmphdLsxq/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmphdLsxq/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpQC8A1x/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpQC8A1x/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpIAtb4y/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpIAtb4y/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpgGBuFn/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpgGBuFn/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp5kfbXR/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp5kfbXR/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmps9zDpZ/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmps9zDpZ/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpGnKyc9/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpGnKyc9/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpPxJS4d/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpPxJS4d/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpWejKVD/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpWejKVD/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpMM8A0d/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpMM8A0d/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpEFwNFn/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpEFwNFn/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpYcFIbo/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpYcFIbo/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpIxYBPA/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpIxYBPA/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpK8taoo/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpK8taoo/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpLdAFdh/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpLdAFdh/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp1xTmAI/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmp1xTmAI/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpu4U7bF/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpu4U7bF/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING (theano.gof.cmodule): Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpN9ND8H/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /Users/SendIt/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/tmpN9ND8H/key.pkl because the corresponding module is gone from the file system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Step time: 23.967981 milliseconds\n",
      "Epochs: 5, TrainingSamples: 8000, ModelTime: 20160414100642\n",
      "1) ExamplesSeen=7200, TrainLoss=0.6007, ValLoss=0.5784, ValR2=-0.0053, ValRMSE=0.2874, TrainTime=2.58 min, EndTime=10:09:24\n",
      "2) ExamplesSeen=14400, TrainLoss=0.6720, ValLoss=0.6241, ValR2=-0.0809, ValRMSE=0.2986, TrainTime=2.60 min, EndTime=10:12:07\n",
      "3) ExamplesSeen=21600, TrainLoss=0.6273, ValLoss=0.6244, ValR2=-0.0466, ValRMSE=0.2987, TrainTime=2.68 min, EndTime=10:14:53\n",
      "4) ExamplesSeen=28800, TrainLoss=0.6912, ValLoss=0.6755, ValR2=-0.1622, ValRMSE=0.3106, TrainTime=2.62 min, EndTime=10:17:37\n",
      "5) ExamplesSeen=36000, TrainLoss=0.6099, ValLoss=0.6051, ValR2=-0.0099, ValRMSE=0.2940, TrainTime=2.67 min, EndTime=10:20:23\n",
      "\n",
      "Finished.  Total train time = 0.23 hours\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from utils_yp import *\n",
    "from datetime import datetime\n",
    "from gru_theano_yp import GRUTheanoYP\n",
    "\n",
    "LEARNING_RATE = float(os.environ.get(\"LEARNING_RATE\", \"0.001\"))\n",
    "DECAY_RATE = float(os.environ.get(\"DECAY_RATE\", \"0.9\"))\n",
    "VEG_INDEX_SIZE = int(os.environ.get(\"VEG_INDEX_SIZE\", \"1\"))\n",
    "HIDDEN_DIM = int(os.environ.get(\"HIDDEN_DIM\", \"128\"))\n",
    "NEPOCH = int(os.environ.get(\"NEPOCH\", \"5\"))\n",
    "\n",
    "def train_with_sgd(model, X_train, y_train, X_test, y_test, nepoch=20, learning_rate=0.001, decay=0.9):\n",
    "    # Set start of training time\n",
    "    start_time = time.time()\n",
    "    # Set model time\n",
    "    modeltime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    print 'Epochs: %d, TrainingSamples: %s, ModelTime: %s' %(nepoch, y_train.shape[0], modeltime)      \n",
    "    # Set epoch variables\n",
    "    min_loss = 100000\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    num_examples_seen = 0\n",
    "    #start epoch\n",
    "    for epoch in range(nepoch):\n",
    "        epoch_start = time.time()\n",
    "        # divide data\n",
    "        train_data, train_labels, val_data, val_labels = shuffle_data(0.9, X_train, y_train)\n",
    "        # For each training example...\n",
    "        for i in range(len(train_data)):\n",
    "            # One SGD step\n",
    "            model.sgd_step(train_data[i], train_labels[i], learning_rate, decay)\n",
    "            num_examples_seen += 1\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        # Calculate training loss\n",
    "        train_loss = model.calculate_loss(train_data, train_labels)\n",
    "        train_losses.append((num_examples_seen, train_loss))\n",
    "        # Calculate validation loss, R-squared, and RMSE\n",
    "        val_loss = model.calculate_loss(val_data, val_labels)\n",
    "        val_losses.append((num_examples_seen, val_loss))\n",
    "        val_predictions = []\n",
    "        for i in range(len(val_data)):\n",
    "            val_predictions.append(model.predict(val_data[i]))\n",
    "        val_predictions = np.reshape(val_predictions, (len(val_predictions), len(val_predictions[0])))\n",
    "#         print val_predictions\n",
    "        val_R_squared = 1 - np.sum(np.square(val_predictions - val_labels))/np.sum(np.square(val_labels - np.mean(val_labels)))\n",
    "        val_rmse = np.sqrt(np.mean(np.square(val_predictions - val_labels)))\n",
    "        # If validation loss is a new minimum, save predictions and model   \n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            # Make and save predictions\n",
    "            X_test_predictions = []\n",
    "            for i in range(len(X_test)):\n",
    "                X_test_predictions.append(np.append(model.predict(X_test[i]).reshape(len(X_test[i])), float(y_test[i][0])))\n",
    "            predictions_and_labels = np.asarray(X_test_predictions)\n",
    "            filename = \"./predictions/GRUs/pred-%s.txt\" %(modeltime)\n",
    "            np.savetxt(filename, predictions_and_labels, fmt='%.18f', delimiter=',',)\n",
    "            # Save model parameters\n",
    "            filename = \"./models/GRUs/GRU-%s.npz\" % (modeltime)\n",
    "            save_model_parameters_theano(model, filename)\n",
    "        # Print epoch stats\n",
    "        print '%d) ExamplesSeen=%d, TrainLoss=%.4f, ValLoss=%.4f, ValR2=%.4f, ValRMSE=%.4f, TrainTime=%.2f min, EndTime=%s' %(epoch+1, num_examples_seen, train_loss, val_loss, val_R_squared, val_rmse, epoch_time/60, time.strftime(\"%I:%M:%S\"))\n",
    "    # Make final predictions    \n",
    "    X_test_predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        X_test_predictions.append(np.append(model.predict(X_test[i]).reshape(len(X_test[i])), float(y_test[i][0])))\n",
    "        final_predictions = np.asarray(X_test_predictions)\n",
    "    print '\\nFinished.  Total train time = %.2f hours' %((time.time() - start_time)/3600)\n",
    "    \n",
    "    return final_predictions, train_losses, val_losses\n",
    "    \n",
    "# Build model\n",
    "model = GRUTheanoYP(VEG_INDEX_SIZE, hidden_dim=HIDDEN_DIM, bptt_truncate=-1)\n",
    "\n",
    "# Run one SGD step and print run-time\n",
    "t1 = time.time()\n",
    "model.sgd_step(X_train[10], Y_train[10], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print \"SGD Step time: %f milliseconds\" % ((t2 - t1) * 1000.)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Train the model\n",
    "final_predictions, train_losses, val_losses = train_with_sgd(model, X_train, log_Y_train, X_test, log_Y_test, nepoch=NEPOCH, learning_rate=LEARNING_RATE, decay=DECAY_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance Stats on Holdout Sample\n",
    "These are the predictions on a holdout sample (X_test above) using the model with the lowest validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Transformed Yield Results:\n",
      "t-6) R-Squared: -0.0050, MAE: 0.2450, RMSE: 0.2985, MAPE: 25.14%\n",
      "t-5) R-Squared: -0.0001, MAE: 0.2451, RMSE: 0.2978, MAPE: 25.43%\n",
      "t-4) R-Squared: 0.0004, MAE: 0.2454, RMSE: 0.2977, MAPE: 25.61%\n",
      "t-3) R-Squared: 0.0015, MAE: 0.2453, RMSE: 0.2975, MAPE: 25.81%\n",
      "t-2) R-Squared: 0.0013, MAE: 0.2453, RMSE: 0.2976, MAPE: 25.94%\n",
      "t-1) R-Squared: 0.0008, MAE: 0.2453, RMSE: 0.2976, MAPE: 26.08%\n",
      "t-0) R-Squared: 0.0000, MAE: 0.2453, RMSE: 0.2978, MAPE: 26.18%\n",
      "\n",
      "Values Transformed Back to Original Units Results:\n",
      "t-6) R-Squared: -0.0570, MAE: 0.7588, RMSE: 0.9956, MAPE: 24.22%\n",
      "t-5) R-Squared: -0.0429, MAE: 0.7591, RMSE: 0.9889, MAPE: 24.51%\n",
      "t-4) R-Squared: -0.0369, MAE: 0.7598, RMSE: 0.9861, MAPE: 24.69%\n",
      "t-3) R-Squared: -0.0286, MAE: 0.7596, RMSE: 0.9821, MAPE: 24.89%\n",
      "t-2) R-Squared: -0.0238, MAE: 0.7595, RMSE: 0.9798, MAPE: 25.03%\n",
      "t-1) R-Squared: -0.0191, MAE: 0.7595, RMSE: 0.9776, MAPE: 25.17%\n",
      "t-0) R-Squared: -0.0162, MAE: 0.7596, RMSE: 0.9762, MAPE: 25.28%\n",
      "\n",
      "Original Y_test Results (should match results above):\n",
      "t-6) R-Squared: -0.0570, MAE: 0.7588, RMSE: 0.9956, MAPE: 24.22%\n",
      "t-5) R-Squared: -0.0429, MAE: 0.7591, RMSE: 0.9889, MAPE: 24.51%\n",
      "t-4) R-Squared: -0.0369, MAE: 0.7598, RMSE: 0.9861, MAPE: 24.69%\n",
      "t-3) R-Squared: -0.0286, MAE: 0.7596, RMSE: 0.9821, MAPE: 24.89%\n",
      "t-2) R-Squared: -0.0238, MAE: 0.7595, RMSE: 0.9798, MAPE: 25.03%\n",
      "t-1) R-Squared: -0.0191, MAE: 0.7595, RMSE: 0.9776, MAPE: 25.17%\n",
      "t-0) R-Squared: -0.0162, MAE: 0.7596, RMSE: 0.9762, MAPE: 25.28%\n"
     ]
    }
   ],
   "source": [
    "y_hat = []\n",
    "y_test = []\n",
    "with open('./predictions/GRUs/pred-20160414100642.txt', 'r') as csvfile:\n",
    "    datareader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in datareader:\n",
    "        label = row.pop()\n",
    "        y_hat.append(row)\n",
    "        y_test.append(label)\n",
    "\n",
    "### OR ###\n",
    "# y_hat = []\n",
    "# y_test = []\n",
    "# for row in final_predictions:\n",
    "#     y_hat.append(row[:-1])\n",
    "#     y_test.append(row[-1])\n",
    "### END OR ###\n",
    "\n",
    "# Results keeping predictions as logs of yield\n",
    "y_hat = np.array(y_hat).astype(np.float)\n",
    "y_test = np.array(y_test).astype(np.float)\n",
    "y_bar = np.mean(y_test)\n",
    "\n",
    "R_squared_list_tr = []\n",
    "mae_list_tr = []\n",
    "rmse_list_tr = []\n",
    "mape_list_tr = []\n",
    "\n",
    "print 'Log-Transformed Yield Results:'\n",
    "for j in range(len(y_hat[0])):\n",
    "    y_hat_last = y_hat[:, j]\n",
    "    R_squared = 1 - np.sum(np.square(y_hat_last - y_test))/np.sum(np.square(y_test - y_bar))\n",
    "    mae = np.mean(np.abs(y_hat_last - y_test))\n",
    "    rmse = np.sqrt(np.mean(np.square(y_hat_last - y_test)))\n",
    "    count = 0\n",
    "    sums = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] != 0: \n",
    "            error = np.divide(abs(y_hat_last[i] - y_test[i]), abs(y_test[i]))\n",
    "            count += 1\n",
    "            sums += error\n",
    "    mean_abs_pct_error = sums/count\n",
    "    R_squared_list_tr.append(R_squared)\n",
    "    mae_list_tr.append(mae)\n",
    "    rmse_list_tr.append(rmse)\n",
    "    mape_list_tr.append(mean_abs_pct_error)\n",
    "    print 't-%d) R-Squared: %.4f, MAE: %.4f, RMSE: %.4f, MAPE: %.2f%s' %(6-j, R_squared, mae, rmse, mean_abs_pct_error*100, '%')\n",
    "    \n",
    "    \n",
    "# Results transforming predictions and yields back to original units\n",
    "y_hat = np.array(y_hat).astype(np.float)\n",
    "y_test = np.array(y_test).astype(np.float)\n",
    "# y_bar = np.mean(y_test)\n",
    "\n",
    "y_hat_exp = np.exp(y_hat)\n",
    "y_test_exp = np.exp(y_test)\n",
    "y_bar_exp = np.mean(y_test_exp)\n",
    "\n",
    "R_squared_list_exp = []\n",
    "mae_list_exp = []\n",
    "rmse_list_exp = []\n",
    "mape_list_exp = []\n",
    "\n",
    "print '\\nValues Transformed Back to Original Units Results:'\n",
    "for j in range(len(y_hat_exp[0])):\n",
    "    y_hat_last = y_hat_exp[:, j]\n",
    "    R_squared = 1 - np.sum(np.square(y_hat_last - y_test_exp))/np.sum(np.square(y_test_exp - y_bar_exp))\n",
    "    mae = np.mean(np.abs(y_hat_last - y_test_exp))\n",
    "    rmse = np.sqrt(np.mean(np.square(y_hat_last - y_test_exp)))\n",
    "    count = 0\n",
    "    sums = 0\n",
    "    for i in range(len(y_test_exp)):\n",
    "        if y_test_exp[i] != 0: \n",
    "            error = np.divide(abs(y_hat_last[i] - y_test_exp[i]), abs(y_test_exp[i]))\n",
    "            count += 1\n",
    "            sums += error\n",
    "    mean_abs_pct_error = sums/count\n",
    "    R_squared_list_exp.append(R_squared)\n",
    "    mae_list_exp.append(mae)\n",
    "    rmse_list_exp.append(rmse)\n",
    "    mape_list_exp.append(mean_abs_pct_error)\n",
    "    print 't-%d) R-Squared: %.4f, MAE: %.4f, RMSE: %.4f, MAPE: %.2f%s' %(6-j, R_squared, mae, rmse, mean_abs_pct_error*100, '%')\n",
    "\n",
    "    \n",
    "# Results using original Y_test\n",
    "y_hat = np.array(y_hat).astype(np.float)\n",
    "# y_test = np.array(y_test).astype(np.float)\n",
    "\n",
    "y_hat_exp = np.exp(y_hat)\n",
    "y_test_orig = Y_test[:, 0]\n",
    "y_bar_orig = np.mean(y_test_orig)\n",
    "\n",
    "R_squared_list_orig = []\n",
    "mae_list_orig = []\n",
    "rmse_list_orig = []\n",
    "mape_list_orig = []\n",
    "\n",
    "print '\\nOriginal Y_test Results (should match results above):'\n",
    "for j in range(len(y_hat_exp[0])):\n",
    "    y_hat_last = y_hat_exp[:, j]\n",
    "    R_squared = 1 - np.sum(np.square(y_hat_last - y_test_orig))/np.sum(np.square(y_test_orig - y_bar_orig))\n",
    "    mae = np.mean(np.abs(y_hat_last - y_test_orig))\n",
    "    rmse = np.sqrt(np.mean(np.square(y_hat_last - y_test_orig)))\n",
    "    count = 0\n",
    "    sums = 0\n",
    "    for i in range(len(y_test_orig)):\n",
    "        if y_test_orig[i] != 0: \n",
    "            error = np.divide(abs(y_hat_last[i] - y_test_orig[i]), abs(y_test_orig[i]))\n",
    "            count += 1\n",
    "            sums += error\n",
    "    mean_abs_pct_error = sums/count\n",
    "    R_squared_list_orig.append(R_squared)\n",
    "    mae_list_orig.append(mae)\n",
    "    rmse_list_orig.append(rmse)\n",
    "    mape_list_orig.append(mean_abs_pct_error)\n",
    "    print 't-%d) R-Squared: %.4f, MAE: %.4f, RMSE: %.4f, MAPE: %.2f%s' %(6-j, R_squared, mae, rmse, mean_abs_pct_error*100, '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Reloading the Saved Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model model from ./models/GRUs/GRU-20160414100642.npz with hidden_dim=128 word_dim=1\n"
     ]
    }
   ],
   "source": [
    "from utils_yp import *\n",
    "\n",
    "model = load_model_parameters_theano(\"./models/GRUs/GRU-20160414100642.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
